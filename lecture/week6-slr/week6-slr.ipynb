{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Science Concepts and Analysis\n",
    "\n",
    "### Week 6: The simple linear model\n",
    "\n",
    "* Statistical models\n",
    "* The simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Project comments\n",
    "\n",
    "This week you and your group should be looking around for a dataset you'd like to work with and getting started on your plan report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The data should meet some minimum requirements:\n",
    "\n",
    "* less than 100MB raw file;\n",
    "* some documentation available;\n",
    "* at least 100 observations x 4 variables (tidy);\n",
    "* no more than 100K observations x 100 variables (tidy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The plan report requires you to tidy up the data, but is otherwise mostly a description of the dataset and background information.\n",
    "* mainly a chance to get feedback from us;\n",
    "* there's a template you can fill out as you go;\n",
    "* your plan doesn't have to pan out, and that's okay -- you can't know what an analysis will produce before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## This week: the simple linear model\n",
    "\n",
    "**Objective**: introduce statistical models in general and the simple linear model in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Statistical models**\n",
    "    + What makes a model 'statistical'?\n",
    "    + Goals of modeling: prediction, description, and inference\n",
    "    + When to avoid models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **The simple linear model**\n",
    "    + Line of best fit by least squares\n",
    "    + A model for the error distribution\n",
    "    + The simple linear model\n",
    "    + Interpretation of estimates\n",
    "    + Uncertainty quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Statistical models\n",
    "\n",
    "+ What makes a model 'statistical'?\n",
    "+ Goals of modeling: prediction, description, and inference\n",
    "+ When to avoid models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Models, in general\n",
    "\n",
    "> A model is an idealized representation of a system. You likely use models every day. For instance, a weather forecast is [based on] a model. (PTDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is a pretty general definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In the context of quantitative fields, a **model** is typically a _**mathematical description**_ of some system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So what makes a model a *statistical* one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What makes a model 'statistical'?\n",
    "\n",
    "One straightforward view is that a **statistical model** is simply a _**probability distribution for a dataset**_. Under this view:\n",
    "> A statistical model represents [a random] data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The word *process* is important there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* For a probability distribution to provide a sensible description of a dataset, one needs to be able to at least imagine collecting multiple datasets with the same basic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* So implicit in any statistical model there's an idea of a fixed *process* by which the data are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "That's why we spent all that time talking about sampling design! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* A good sampling design fixes the process by which data are collected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* That makes it possible to use statistical models in a meaningful way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Simple example: univariate models\n",
    "\n",
    "All the distributions you learned in 120A are very simple statistical models for univariate data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "For example, suppose you have a dataset comprising the number of meteorites that hit earth on each of 225 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The Poisson distribution provides one possible model for the data -- specifically, that the counts are independent Poisson random variables.\n",
    "\n",
    "<img src = 'figures/fig0a-pois.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "But it doesn't quite match the distribution of values closely enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Simple example\n",
    "\n",
    "The negative binomial does much better here:\n",
    "\n",
    "<img src = 'figures/fig0b-nbinom.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Why model the data-generating process?\n",
    "\n",
    "A good description of a data-generating process usually captures two aspects of a system:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* the deterministic aspects, allowing one to identify structure in the data; and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* the random aspects or 'noise', allowing one to quantify uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In the univariate example, the better model captured both the most common value (a kind of structure) and the variation (noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Modeling goals\n",
    "\n",
    "Models serve one of three main purposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Prediction**: predict new data before it is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Inference**: make conclusions about a larger population than the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* **Description**: less common, but sometimes models provide a convenient description of observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We probably wouldn't use a univariate model in a predictive capacity, but one could be used to make an inference -- we could estimate the probability that over 40 meteorites (rarely observed) hit earth any given day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Models you've seen already\n",
    "\n",
    "The exploratory analysis techniques you've seen are actually very flexible models often used for descriptive purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Kernel density estimates are models for univariate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* LOESS curves are models for trends in bivariate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Principal components are models for correlation structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "It's a little tricky to see, but these correspond to *classes* of probability distributions rather than specific ones. That's why they're so flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## It's okay not to model data\n",
    "\n",
    "There are a lot of situations when modeling simply isn't appropriate or feasible. Two especially common scenarios are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Sketchy sampling**\n",
    "\n",
    "Every statistical model makes some set of assumptions that translate to specific ways data were collected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These don't always need to hold exactly, but it's probably best to consider other possibilities if:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* the way data were collected is highly opaque or nonsystematic;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* the sampling design or measurement procedures have serious flaws or inconsistencies;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* you have no information whatsoever about the data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Sparse data**\n",
    "\n",
    "Fitted models are highly variable (sensitive to the specific dataset, and so less reliable) with small quantities of data. Typically, most models only require modest amounts of data for reliable fitting, perhaps as few as 10-15 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "It's probably best to seek other strategies when the number of observations is exceedingly low relative to the modeling objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The simple linear model\n",
    "+ Line of best fit by least squares\n",
    "+ The error distribution\n",
    "+ The simple linear model\n",
    "+ Interpretation of estimates\n",
    "+ Uncertainty quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## A familiar example\n",
    "\n",
    "In HW2, you generated this plot:\n",
    "\n",
    "<img src = 'figures/fig1-hw2plot.png' style = 'width:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "You may not have realized it at the time, but those lines are *simple linear models*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* They describe the mean gaps as linear functions of log median income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Applications of linear models\n",
    "\n",
    "Linear models can be used for prediction, inference, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Predict the gender achievement gaps for a new district based on median income in the district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Quantify the association between median income and achievement gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We're going to talk in detail about the model itself:\n",
    "* definition;\n",
    "* estimation;\n",
    "* assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data setting\n",
    "\n",
    "Let's first introduce the kind of data that the simple linear model describes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* There are two variables, $X$ and $Y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* The data values are $n$ observations of these two variables:\n",
    "$$(x_1, y_1), \\dots, (x_n, y_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The notation in tuples indicates the pairing of the values when measured on the same observational unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "If it helps, think of the tuples as an alternative description of a dataframe with $n$ rows and $2$ columns:\n",
    "\n",
    "$X$ | $Y$\n",
    "---|---\n",
    "$x_1$ | $y_1$\n",
    "$x_2$ | $y_2$\n",
    "$\\vdots$ | $\\vdots$\n",
    "$x_n$ | $y_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data setting\n",
    "\n",
    "The notation above is just a mathematical description of data that looks like this:\n",
    "\n",
    "<img src = 'figures/fig2-mathgap.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In our notation, $X$ would represent log median income, and $Y$ would represent the math gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data setting\n",
    "\n",
    "So to better align the notation we'll be using with our example, the data in tabular form are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_income</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600001</th>\n",
       "      <td>11.392048</td>\n",
       "      <td>-0.562855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600006</th>\n",
       "      <td>11.607236</td>\n",
       "      <td>0.061163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600011</th>\n",
       "      <td>10.704570</td>\n",
       "      <td>-0.015417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_income       gap\n",
       "id                          \n",
       "600001   11.392048 -0.562855\n",
       "600006   11.607236  0.061163\n",
       "600011   10.704570 -0.015417"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import grade-aggregated seda data from hw2\n",
    "seda = pd.read_csv('data/seda.csv')\n",
    "\n",
    "# filter to math and remove NaNs\n",
    "regdata = seda[seda.subject == 'math'].dropna().drop(columns = 'subject').set_index('id')\n",
    "regdata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, p = regdata.shape\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The tuples would be:\n",
    "$$(\\text{log_income}_1, \\text{gap}_1)\\;,\\; (\\text{log_income}_2, \\text{gap}_2)\\;,\\; \\dots\\;,\\; (\\text{log_income}_{625}, \\text{gap}_{625})$$\n",
    "\n",
    "Or more specifically:\n",
    "$$(11.392, -0.563)\\;,\\; (11.607, 0.061)\\;,\\; \\dots\\;,\\; (11.229, -0.040)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Lines and data\n",
    "\n",
    "A line in slope-intercept form is given by the equation:\n",
    "$$y = ax + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Data values never fall exactly on a line.** So in general for every $a, b$:\n",
    "$$y_i \\neq a x_i + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**But** we can describe any dataset as a line and a 'residual':\n",
    "$$y_i = \\underbrace{a x_i + b}_\\text{line} \\underbrace{+\\;e_i}_\\text{residual}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Lines and data\n",
    "\n",
    "Here's a picture:\n",
    "\n",
    "<img src = 'figures/fig3-resids.png' style = 'width:700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Each *residual* is simply the vertical distance of a value of $Y$ from the line: \n",
    "$$\\color{grey}{e_i} = \\color{blue}{y_i} - \\color{red}{(a x_i + b)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Many possible lines\n",
    "\n",
    "This makes it possible to express $Y$ as a linear function of $X$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "However, the mathematical description is somewhat tautological, since for *any* $a, b$, there are residuals $e_1, \\dots, e_n$ such that\n",
    "\n",
    "$$y_i = a x_i + b + e_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In other words, there are **infinitely many possible lines**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So, which values of $a$ and $b$ should be chosen for a given set of data values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## The least squares line\n",
    "\n",
    "A sensible criterion is to find the line for which:\n",
    "* the average residual $\\bar{e}$ is zero; and\n",
    "* the residuals vary the least. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "If $\\bar{e} = 0$, then the residual variance is:\n",
    "$$\\frac{1}{n - 1}\\sum_{i = 1}^n (e_i - \\bar{e})^2 = \\frac{1}{n - 1}\\sum_{i = 1}^n e_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So the values of $a, b$ that minimize the *sum of squared residuals* give the 'best' line (in one sense of the word 'best'):\n",
    "$$(a^*, b^*) = \\arg\\min_{(a, b)}\\left\\{\\sum_{i = 1}^n \\underbrace{\\left(y_i - (a x_i + b)\\right)^2}_{e_i^2}\\right\\}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is known as the **least squares line**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Calculating the least squares line\n",
    "\n",
    "The least squares solution $(a^*, b^*)$ has a unique closed form. The line can be written in matrix form as $\\mathbf{y} = \\mathbf{Xa} + \\mathbf{e}$, where:\n",
    "\n",
    "$$\\underbrace{\\left[\\begin{array}{c} y_1 \\\\\\vdots\\\\ y_n \\end{array}\\right]}_{\\mathbf{y}}\n",
    "    = \\underbrace{\\left[\\begin{array}{cc} \n",
    "        1 & x_1 \\\\\n",
    "        \\vdots & \\vdots \\\\\n",
    "        1 & x_n\n",
    "        \\end{array}\\right]}_{\\mathbf{X}}\n",
    "      \\underbrace{\\left[\\begin{array}{c} a \\\\ b \\end{array}\\right]}_{\\mathbf{a}}\n",
    "      + \\underbrace{\\left[\\begin{array}{c} e_1 \\\\\\vdots\\\\ e_n \\end{array}\\right]}_{\\mathbf{e}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Then, the sum of squared residuals is:\n",
    "$$\\mathbf{e'e} = (\\mathbf{y} - \\mathbf{Xa})'(\\mathbf{y} - \\mathbf{Xa})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Using vector calculus, one can show that:\n",
    "$$\\nabla_\\mathbf{a} \\mathbf{e'e} = 0 \\quad\\Longrightarrow\\quad 2\\mathbf{X'y} = 2\\mathbf{X'Xa} \\quad\\Longrightarrow\\quad \\mathbf{a} = (\\mathbf{X'X})^{-1}\\mathbf{X'y}$$\n",
    "And that this is a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The solution $\\mathbf{a} = (\\mathbf{X'X})^{-1}\\mathbf{X'y}$ is known as the **ordinarly least squares** (OLS) solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Computation\n",
    "\n",
    "Luckily, most software efficiently computes OLS solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35616996,  0.12105696])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save explanatory variable and response variable separately as arrays\n",
    "x = regdata.log_income.values[:, np.newaxis]\n",
    "y = regdata.gap.values\n",
    "\n",
    "# configure regression module\n",
    "slr = LinearRegression()\n",
    "\n",
    "# fit slr model\n",
    "slr.fit(x, y)\n",
    "\n",
    "# store estimates\n",
    "slope, intercept = slr.coef_, slr.intercept_\n",
    "\n",
    "ols = np.append(intercept, slope)\n",
    "ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can check the calculations by computing the closed-form expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35616996,  0.12105696])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ols solution, by hand\n",
    "x_mx = np.vstack([np.repeat(1, len(x)), x[:, 0]]).transpose() # X\n",
    "xtx = x_mx.transpose().dot(x_mx) # X'X\n",
    "xtx_inv = np.linalg.inv(xtx) # (X'X)^{-1}\n",
    "xtx_inv.dot(x_mx.transpose()).dot(y) # (X'X)^{-1} X'y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Plotting\n",
    "\n",
    "The OLS solution can then be used to connect a grid of evenly-spaced points for plotting the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of values for plotting\n",
    "line_df = pd.DataFrame({'log_income': np.linspace(x.min(), x.max(), 500)})\n",
    "line_df['gap'] = line_df.log_income*slope + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Compare the result of layering a line plot of `line_df` on the data scatter (left) with the regression transform from Altair (right):\n",
    "\n",
    "<img src = 'figures/fig4-olsline.png' style = 'width:700px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## OLS is not a statistical model (yet)\n",
    "\n",
    "The least squares line is simply an algebraic transformation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is not yet a statistical model, since there is no probability distribution involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can change that by considering the residuals to be random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Residual distribution\n",
    "\n",
    "Have a look at the histogram of the residuals (with a KDE curve):\n",
    "\n",
    "<img src = 'figures/fig5a-residhist.png' style = 'width: 400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Does this look like any probability density function you encountered in 120A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Residual distribution\n",
    "\n",
    "The residual distribution is pretty well-approximated by the *normal* or *Gaussian* distribution:\n",
    "\n",
    "<img src = 'figures/fig5b-residnormal.png' style = 'width: 400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## The error model\n",
    "\n",
    "This phenomenon -- nearly normal residuals -- is pretty robust. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So a standard **error model** for the residuals is that they are independent normal random variables. This is written as:\n",
    "\n",
    "$$e_i \\stackrel{iid}{\\sim} N\\left(0, \\sigma^2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "This is an important modification because it induces a probability distribution on $y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "In other words, it makes the linear description of $Y$ into a statistical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## The simple linear model\n",
    "\n",
    "Now we're in a position to state the **simple linear model**:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad\\begin{cases} i = 1, \\dots, n \\\\\\epsilon_i \\sim N\\left(0,\\sigma^2\\right)\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Terminology**\n",
    "* $y_i$ is the _**response variable**_\n",
    "* $x_i$ is the _**explanatory variable**_\n",
    "* $\\epsilon_i$ is the _**error**_\n",
    "* $\\beta_0, \\beta_1, \\sigma^2$ are the _**model parameters**_\n",
    "    + $\\beta_0$ is the _**intercept**_\n",
    "    + $\\beta_1$ is the _**coefficient**_\n",
    "    + $\\sigma^2$ is the _**error variance**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Model implications\n",
    "\n",
    "Treating the error term as random has a number of implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Normality) The response is a normal random variable: $y_i \\sim N\\left(\\beta_0 + \\beta_1 x_i, \\sigma^2\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Linearity) The mean response is linear in $X$: $\\mathbb{E}y_i = \\beta_0 + \\beta_1 x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Constant variance) The response has variance: $\\text{var}y_i = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Independence) The observations are independent (because the errors are): $y_i \\perp y_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These are the **assumptions** of the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Aside*: other error distributions, or conditions that don't assume a specific distribution, are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Estimates\n",
    "\n",
    "The OLS solution has a number of optimality properties with respect to the simple linear model -- in other words, it's the best estimate of the parameters $\\beta_0, \\beta_1$ under many conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "You've already seen how to compute the OLS estimates. These are typically denoted by the corresponding paramater with a hat:\n",
    "\n",
    "$$\\hat{\\beta} = \\left[\\begin{array}{c}\\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{array}\\right] = (\\mathbf{X'X})^{-1}\\mathbf{X'y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "An estimate of the error variance is:\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{1}{n - 2} \\sum_{i = 1}^n \\left(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i\\right)^2 = \\frac{1}{n - 2}\\left(\\mathbf{y} - \\mathbf{X}\\hat{\\beta}\\right)'\\left(\\mathbf{y} - \\mathbf{X}\\hat{\\beta}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Fitted values and residuals\n",
    "\n",
    "Once estimates are computed, the projections of the data points onto the line are known as **fitted values**: they are _**the estimated values of the response variable for each data point**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These are typically denoted $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$ and computed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted values\n",
    "fitted = slr.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The **model residuals** are then _**the difference between observed and fitted values**_: $y_i - \\hat{y}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Parameter interpretations\n",
    "\n",
    "Let's go back to the SEDA example. The parameter estimates were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35616996,  0.12105696])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Since $\\mathbb{E}y_i = \\beta_0 + \\beta_1 x_i$, these are interpreted as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Intercept) When median district income is 1 dollar ($x_i = 0$), the mean achievement gap ($\\mathbb{E}y_i$) is estimated to be 1.356 standard deviations of the national average in favor of girls.\n",
    "    + (Not of particular interest here because no districts have a median income of 1 USD.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Slope) Every doubling of median income is associated with an estimated increase in the mean achievement gap of 0.084 standard deviations of the national average in favor of boys.\n",
    "    + $\\hat{\\beta}_1\\log (2x) = \\hat{\\beta}_1\\log x + \\hat{\\beta}_1 \\log 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08391029103902604"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols[1]*np.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## General parameter interpretations\n",
    "\n",
    "There is some general language for interpreting the parameter estimates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Intercept) [at $x_i = 0$] the mean [response variable] is estimated to be [$\\hat{\\beta}_0$ units]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* (Slope) Every [one-unit increase in $x_i$] is associated with an estimated change in mean [response variable] of [$\\hat{\\beta}_1$ units]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "You can use this standard language as a formulaic template for interpreting estimated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Uncertainty quantification\n",
    "\n",
    "A great benefit of the simple linear model relative to a best-fit line is that the error variance allows for *uncertainty quantification*.\n",
    "\n",
    "What that means is that one can describe precisely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* variation in the estimates (*i.e.*, estimated model reliability);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* variation in predictions made using the estimated model (*i.e.*, predictive reliability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Understanding variation in estimates\n",
    "\n",
    "What would happen to the estimates if they were computed from a different sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We can explore this idea a little by calculating OLS estimates from *subsamples* of the dataset.\n",
    "\n",
    "<img src = 'figures/fig6-subsamples.png' style = 'width: 400px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The lines are pretty similar, but they change a bit from subsample to subsample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So, a useful question is: *by how much should one expect the estimates to change depending on the data they are fit to?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Variance of parameter estimates\n",
    "\n",
    "Under the simple linear model, the estimated parameters have calculable variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "It can be shown that:\n",
    "\n",
    "$$\\left[\\begin{array}{cc} \n",
    "    \\text{var}\\hat{\\beta}_0 & \\text{cov}\\left(\\hat{\\beta}_0, \\hat{\\beta}_1\\right) \\\\ \n",
    "    \\text{cov}\\left(\\hat{\\beta}_0, \\hat{\\beta}_1\\right) &\\text{var}\\hat{\\beta}_1\n",
    "    \\end{array}\\right]\n",
    "   = \\sigma^2 \\left(\\mathbf{X'X}\\right)^{-1}$$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So the variances can be *estimated* by plugging in $\\color{red}{\\hat{\\sigma}^2}$. The estimated standard deviations are known as *standard errors*:\n",
    "\n",
    "$$\\text{SE}(\\hat{\\beta}_0) = \\sqrt{\\color{red}{\\hat{\\sigma}^2}(\\mathbf{X'X})^{-1}_{11}} \\qquad\\text{and}\\qquad \\text{SE}(\\hat{\\beta}_1) = \\sqrt{\\color{red}{\\hat{\\sigma}^2}(\\mathbf{X'X})^{-1}_{22}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "About 95% of the time, the true values will be within 2SE of any particular estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## So was the gap estimate a fluke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09498451,  0.14472448],\n",
       "       [-1.61735541,  0.09738944]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# residuals\n",
    "resid = y - fitted\n",
    "\n",
    "# residual SE\n",
    "n = len(x)\n",
    "p = 2\n",
    "resid_se = np.sqrt(resid.var()*(n - 1)/(n - p))\n",
    "\n",
    "# coefficient variances/covariances\n",
    "x_mx = np.vstack([np.repeat(1, n), x[:, 0]]).transpose()\n",
    "coef_vcov = np.linalg.inv(x_mx.transpose().dot(x_mx))*(resid_se**2)\n",
    "\n",
    "# coefficient standard errors\n",
    "coef_se = np.sqrt(coef_vcov.diagonal())\n",
    "\n",
    "# coefficient intervals\n",
    "np.vstack([ols + 2*coef_se, ols - 2*coef_se])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Visual display of uncertainty quantification\n",
    "\n",
    "Often it's easier to get the message across with a plot. \n",
    "\n",
    "It's fairly common practice to add a *band* around the plotted line to indicate estimated variability.\n",
    "\n",
    "<img src = 'figures/fig7-uncertaintyband.png' style = 'width: 500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Predictions for a district not in the dataset can be calculated by simply plugging in the explanatory variable for the new observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "If for example, we'd like to predict the mean achievement gap in math for a district with a median income of 86K, we'd use:\n",
    "$$x_{new} = \\log(86000)$$\n",
    "And compute:\n",
    "$$\\hat{y}_{new} = \\hat{\\beta}_0 + \\hat{\\beta}_1\\log(86000) = \\left[\\begin{array}{cc} 1 &\\log(86000) \\end{array}\\right]\\left[\\begin{array}{c}\\hat{\\beta}_0 \\\\ \\hat{\\beta}_1\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019291648586032384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "newobs = np.array([1, np.log(86000)])\n",
    "pred = ols.dot(newobs)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Prediction uncertainty\n",
    "\n",
    "The variance of a predicted observation is given by:\n",
    "$$\\text{var}(\\hat{y}_{new}) = \\sigma^2\\left( 1 + \\mathbf{x}_{new}'(\\mathbf{X'X})^{-1}\\mathbf{x}_{new}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So the estimated standard deviation of the prediction is:\n",
    "$$SE\\left(\\hat{y}_{new}\\right) = \\sqrt{\\hat{\\sigma}^2\\left( 1 + \\mathbf{x}_{new}'(\\mathbf{X'X})^{-1}\\mathbf{x}_{new}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11483333147068375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_se = np.sqrt((resid_se**2)*(1 + newobs.dot(xtx_inv).dot(newobs)))\n",
    "pred_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Again, about 95% of the time the true value will be within 2SE of the estimate. So our *uncertainty* about the prediction is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.21037501435533512, 0.2489583115273999]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pred - 2*pred_se, pred + 2*pred_se]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Prediction uncertainty\n",
    "\n",
    "The prediction uncertainty is considerable, but consistent with the variability we see in the data.\n",
    "\n",
    "<img src = 'figures/fig8-prediction.png' style = 'width: 500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Summary\n",
    "\n",
    "This was our first week on statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* A statistical model is a probability distribution representing a data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* The distributions you know and love from PSTAT120A are all simple models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Our focus was on the **simple linear model**, according to which _**one variable of interest is a linear function of another variable and a random error**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Parameters are estimated by minimizing residual variance (least squares)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* The model assumes normality, linearity, constant variance, and independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Useful for both prediction and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Estimated variance allows for uncertainty quantification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Next week we'll discuss extending this model to cases with *multiple* explanatory variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
